{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"diffusion training data/\"\n",
    "def load_transitions():\n",
    "    import os.path\n",
    "    if not os.path.isfile(save_dir + \"observations.npz\"):\n",
    "        print(\"No saved transitions found\")\n",
    "        return()\n",
    "    #its stored as a dict so grab out the single array. and 0th axis should be the number of transitions\n",
    "    observations = np.load(save_dir + \"observations.npz\")[\"arr_0\"]\n",
    "    actions = np.load(save_dir + \"actions.npz\")[\"arr_0\"]\n",
    "    rewards = np.load(save_dir + \"rewards.npz\")[\"arr_0\"]\n",
    "    dones = np.load(save_dir + \"dones.npz\")[\"arr_0\"]\n",
    "    assert(len(observations) == len(actions) == len(rewards) == len(dones))\n",
    "    print(\"loaded transitions of length\", len(observations))\n",
    "\n",
    "\n",
    "    #crashes on codespaces\n",
    "    # observations = torch.tensor(observations, dtype=torch.float32, device=device)\n",
    "    # actions = torch.tensor(actions, dtype=torch.float32, device=device)\n",
    "    # rewards = torch.tensor(rewards, dtype=torch.float32, device=device)\n",
    "    # dones = torch.tensor(dones, dtype=torch.float32, device=device)\n",
    "\n",
    "    return observations, actions, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded transitions of length 15280\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "observations, actions, rewards, dones = load_transitions()\n",
    "print(observations[0].size, actions[0].size, rewards[0].size, dones[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(in_channels = input_size, out_channels =hidden_size, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the input, hidden, and output sizes\n",
    "input_size = 2 * observations[0].size + actions[0].size() #two screens of pong and the action taken on the last frame\n",
    "hidden_size = 100 #arbitrary\n",
    "output_size = observations[0].size + rewards[0].size() #one screen of pong + the reward\n",
    "\n",
    "# Create an instance of the network\n",
    "net = MyNetwork().to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "# define loss function and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAAAAADoTpQ7AAACEUlEQVR4Ae3dUUrEQBREUSMuS9fhgnU5LkIaFC7DNDyqFJrh5seiSY3h9BsSP4LX08/x/hsO+3lNLuwNF/2BnMZXFD+R78Xne4snrXmB7W68TD9gzR5ncdrbnbdmj7O4O88t3slM1xWcSu3OU3AnM11XcCq1O0/Bncx0/XjB8b34L+/DS29yH17nHS/oBa5tao7R3yTNL2i7bnEreH21n/DPfbe4BVZQwVag7TuDDy/ow8LDb7HfYre4FWj7zqCCrUDbdwYVbAXavjOoYCvQ9p1BBVuBtu8MKtgKtH1nUMFWoO07gwq2Am3fGVSwFWj7zqCCrUDbdwYVbAXavjOoYCvQ9p1BBVuBtu8MKtgKtH1nUMFWoO07gwq2Am3fGXx4wfFra63EpL9eZVuvlvNwBqmRZAUTNXYUpEaSFUzU2FGQGklWMFFjR0FqJPl4waOeB2+fBZf48YJeYPLFYEdBaiRZwUSNHQWpkWQFEzV2FKRGkhVM1NhRkBpJVjBRY0dBaiRZwUSNHQWpkWQFEzV2FKRGkhVM1NhRkBpJVjBRY0dBaiRZwUSNHQWpkWQFEzV2FKRGkhVM1NhRkBpJVjBRY0dBaiRZwUSNHQWpkWQFEzV2FKRGkhVM1NhRkBpJVjBRY0dBaiRZwUSNHQWpkWT/01Wixo4zSI0kK5iosaMgNZKsYKLGjoLUSLKCiRo7ClIjyd9tWgsYNKf3UQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=160x210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image = Image.fromarray(observations[0])\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = []\n",
    "images = [Image.fromarray(observation) for observation in observations]\n",
    "for image in images:\n",
    "    gif.append(image)\n",
    "gif[0].save('temp/result.gif', save_all=True,optimize=False, append_images=gif[1:], loop=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
