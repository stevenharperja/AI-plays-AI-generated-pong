{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lq9gvYDqA1T",
        "outputId": "e77b1986-f0a1-4ba3-e106-5b5b27b065f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.3.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (2.3.0+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (2021.4.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mZKjKkrhqA1V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXB_s-ftr8QY",
        "outputId": "2f115f3c-d581-4f27-fb6f-1607ae005bab"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sqvvOrV3qA1W"
      },
      "outputs": [],
      "source": [
        "save_dir = \"diffusion_training_data/\"\n",
        "#save_dir = '/content/drive/MyDrive/ai ai pong/'+ save_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (2.3.0+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (2.3.0+cu118)\n",
            "Requirement already satisfied: filelock in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (2021.4.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Collecting conditional_diffusion\n",
            "  Cloning https://github.com/stevenharperja/conditional_diffusion.git to c:\\users\\shwes\\appdata\\local\\temp\\pip-install-tjajn2r2\\conditional-diffusion_393235b6a2ec495f97271afcf41ddac1\n",
            "  Resolved https://github.com/stevenharperja/conditional_diffusion.git to commit ce480bac794a41df4a5e88f5d7e04dba876b7fc4\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: numpy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from conditional_diffusion) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from conditional_diffusion) (3.8.4)\n",
            "Requirement already satisfied: torch in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from conditional_diffusion) (2.3.0+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from conditional_diffusion) (0.18.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from conditional_diffusion) (4.66.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from conditional_diffusion) (10.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from matplotlib->conditional_diffusion) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from matplotlib->conditional_diffusion) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from matplotlib->conditional_diffusion) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from matplotlib->conditional_diffusion) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from matplotlib->conditional_diffusion) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from matplotlib->conditional_diffusion) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from matplotlib->conditional_diffusion) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch->conditional_diffusion) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch->conditional_diffusion) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch->conditional_diffusion) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch->conditional_diffusion) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch->conditional_diffusion) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch->conditional_diffusion) (2024.3.1)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch->conditional_diffusion) (2021.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tqdm->conditional_diffusion) (0.4.6)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->conditional_diffusion) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->conditional_diffusion) (2021.12.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->conditional_diffusion) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from jinja2->torch->conditional_diffusion) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from sympy->torch->conditional_diffusion) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/stevenharperja/conditional_diffusion.git 'C:\\Users\\shwes\\AppData\\Local\\Temp\\pip-install-tjajn2r2\\conditional-diffusion_393235b6a2ec495f97271afcf41ddac1'\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchvision\n",
        "# !pip install tensorboard\n",
        "# !pip uninstall conditional_diffusion\n",
        "\n",
        "#install torch with cuda\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install git+https://github.com/stevenharperja/conditional_diffusion.git#egg=conditional_diffusion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.is_available()\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (2.16.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (1.63.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (5.26.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (65.5.0)\n",
            "Requirement already satisfied: six>1.9 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard\n",
        "import conditional_diffusion.modules as modules\n",
        "from conditional_diffusion.ddpm_conditional import Diffusion as Diffusion\n",
        "import conditional_diffusion.utils as utils\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FR9B9rn3qA1Z"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm \n",
        "class Net(nn.Module):\n",
        "    def __init__(self, device, embedding_scale = 0):\n",
        "        super(Net, self).__init__()\n",
        "        self.embedding_scale = embedding_scale\n",
        "\n",
        "        resnet = resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        resnet.fc = nn.Identity()\n",
        "        #freeze the weights for resnet\n",
        "        for param in resnet.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        ###init and modify diffusion model\n",
        "        diffusion_model = modules.UNet_conditional(num_classes=10).to(device)\n",
        "        ckpt = torch.load(\"models/conditional_ema_ckpt.pt\", map_location=device)\n",
        "        diffusion_model.load_state_dict(ckpt)\n",
        "        #remove nn.embedder and just send an embedding instead\n",
        "        diffusion_model.label_emb = nn.Identity()\n",
        "        #freeze the weights for diffusion model\n",
        "        for param in diffusion_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        #unfreeze all of the diffusion model's decoder layers\n",
        "        # diffusion_model.up1.requires_grad = True\n",
        "        # diffusion_model.sa4.requires_grad = True\n",
        "        # diffusion_model.up2.requires_grad = True\n",
        "        # diffusion_model.sa5.requires_grad = True\n",
        "        diffusion_model.up3.requires_grad = True #unfreeze just the last 3 layers of diffusion model\n",
        "        diffusion_model.sa6.requires_grad = True\n",
        "        diffusion_model.outc.requires_grad = True\n",
        "\n",
        "        ###init upscaler model\n",
        "        upscaler = nn.Sequential(\n",
        "            nn.Upsample(size=(224,224), mode=\"bilinear\", align_corners=True),\n",
        "        )\n",
        "\n",
        "        #input of (N, 3, 224, 224), output of (N, 256)\n",
        "        self.encoder = nn.Sequential(\n",
        "            resnet,\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2, padding=0), #Using a layer which isnt trainable so I can reduce the size while keeping it frozen.\n",
        "        )\n",
        "        \n",
        "        self.diffusion_model = diffusion_model #input of (N,256) output of (N,3,64,64)\n",
        "        self.upscaler = upscaler\n",
        "        self.final_layer = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=1, stride=1, padding=0) # reduce channel size to 1 for black and white\n",
        "        #input of (N, 256), output of (N, 1)\n",
        "        self.reward_maker = nn.Sequential(\n",
        "            nn.Linear(in_features=256, out_features=1),\n",
        "        )\n",
        "        #input of (N, 256), output of (N, 1)\n",
        "        self.done_maker = nn.Sequential(\n",
        "            nn.Linear(in_features=256, out_features=1),\n",
        "        )\n",
        "\n",
        "\n",
        "        ###variables for the diffusion model\n",
        "        self.noise_steps = 1000\n",
        "        self.beta_start = 1e-4\n",
        "        self.beta_end = 0.02\n",
        "        self.beta = torch.linspace(self.beta_start, self.beta_end, self.noise_steps).to(device)\n",
        "        self.alpha = 1. - self.beta\n",
        "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
        "        self.device = device\n",
        "        self.zero_embedding = torch.zeros((1,256)).to(self.device) \n",
        "\n",
        "\n",
        "    #prediction function. this may not work for training. but maybe since its pretrained it might? work\n",
        "    def diffusion_sample(self, embedding): # see https://github.com/stevenharperja/conditional_diffusion/blob/main/conditional_diffusion/ddpm_conditional.py#L41\n",
        "        n = embedding.size()[0]\n",
        "        x = torch.randn((n, 3, 64, 64)).to(self.device)\n",
        "        for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
        "            t = (torch.ones(n) * i).long().to(self.device)\n",
        "            predicted_noise = self.diffusion_model(x, t, embedding)\n",
        "            if self.embedding_scale > 0:\n",
        "                uncond_predicted_noise = self.diffusion_model(x, t, None)\n",
        "                predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, self.embedding_scale)\n",
        "            alpha = self.alpha[t][:, None, None, None]\n",
        "            alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
        "            beta = self.beta[t][:, None, None, None]\n",
        "            if i > 1:\n",
        "                noise = torch.randn_like(x)\n",
        "            else:\n",
        "                noise = torch.zeros_like(x)\n",
        "            x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x, t = None, noised_truth = None, use_embedding = True):\n",
        "        \"\"\"\n",
        "        \n",
        "        x: The input image (n,3,224,224)\n",
        "        t: The timesteps vector (n)\n",
        "        noised_truth: a noised version of the target image, used for training (n,3,64,64)\n",
        "        use_embedding: Whether to use the embedding or not, useful for training faster?\n",
        "\n",
        "        \n",
        "        returns:\n",
        "        if training:\n",
        "            it returns a predicted noise, and an upscaled predicted noise, along with a predicted reward and done\n",
        "        if not training\n",
        "            it returns a predicted image, along with a reward and done.\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        embedding = self.zero_embedding.repeat((x.size()[0],1))\n",
        "        if (not self.training) or use_embedding:\n",
        "            embedding = self.encoder(x) #(n,256)       \n",
        "            \n",
        "        unscaled_image = None\n",
        "        if self.training:\n",
        "            if noised_truth == None:\n",
        "                raise Exception(\"Cannot train without a provided noised target image\")\n",
        "            if t == None:\n",
        "                raise Exception(\"Cannot train without a provided timesteps vector\")\n",
        "            unscaled_image = self.diffusion_model(noised_truth,t,embedding) #(n,3,64,64)\n",
        "        else:\n",
        "            unscaled_image = self.diffusion_sample(embedding) #(n,3,64,64) \n",
        "\n",
        "        image = self.upscaler(unscaled_image)\n",
        "        image = self.final_layer(image)#(n,1,224,224)\n",
        "        #if not self.train:\n",
        "        image = (image.clamp(-1, 1) + 1) / 2\n",
        "        image = (image * 255).type(torch.uint8)\n",
        "        rew = self.done_maker(embedding) #(n,1)\n",
        "        don = self.reward_maker(embedding) #(n,1)\n",
        "        if self.training:\n",
        "            return unscaled_image,image,rew,don\n",
        "        else:\n",
        "            return image,rew,don\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an instance of the network\n",
        "net = Net(device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "# from torchvision import datasets\n",
        "# from torchvision.transforms import ToTensor\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "class PongDataset(Dataset):\n",
        "    def __init__(self, dir, device):\n",
        "        self.dir = dir\n",
        "        self.device = device\n",
        "    def __len__(self):\n",
        "        existing_files = [f for f in listdir(self.dir) if isfile(join(self.dir, f))]\n",
        "        if existing_files:\n",
        "            #This grabs the largest integer out of all the filenames (filter the string for digit chars, convert those chars to an int)\n",
        "            i = max(*[int(''.join([i for i in f if i.isdigit()])) for f in existing_files])\n",
        "            return i\n",
        "        else:\n",
        "            return 0\n",
        "    def __getitem__(self, index):\n",
        "        # transitions = np.load(save_dir + \"transitions{i}.npz\".format(index))\n",
        "        # observations = transitions[\"observations\"]\n",
        "        # actions = transitions[\"actions\"]\n",
        "        # rewards = transitions[\"rewards\"]\n",
        "        # dones = transitions[\"dones\"]\n",
        "\n",
        "        #use data which was preformatted for the 'trivial' model\n",
        "        input = torch.load(self.dir+\"input{i}.pt\".format(i=index)).to(self.device)\n",
        "        truth = torch.load(self.dir+\"truth{i}.pt\".format(i=index))\n",
        "        truth = tuple([t.to(self.device)for t in truth])\n",
        "\n",
        "        return input, truth "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0xNQBUhaqA1a"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "trainset = PongDataset(save_dir,device)\n",
        "if __name__ == '__main__':\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)#, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "V2Mqom-GqA1Z"
      },
      "outputs": [],
      "source": [
        "#see https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "# define loss function and optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "small_img_criterion = nn.MSELoss()\n",
        "img_criterion = nn.MSELoss()\n",
        "rew_criterion = nn.MSELoss()\n",
        "don_criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "\n",
        "image_importance = 10 #hyperparameter for weighting how important the image is in the loss function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "beta_start=1e-4\n",
        "beta_end=0.02\n",
        "noise_steps = 1000\n",
        "beta = torch.linspace(beta_start, beta_end, noise_steps).to(device)\n",
        "alpha = 1. - beta\n",
        "alpha_hat = torch.cumprod(alpha, dim=0)\n",
        "def noise_given_noise(x,t,noise):\n",
        "    sqrt_alpha_hat = torch.sqrt(alpha_hat[t])[:, None, None, None]\n",
        "    sqrt_one_minus_alpha_hat = torch.sqrt(1 - alpha_hat[t])[:, None, None, None]\n",
        "    Ɛ = noise\n",
        "    return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
        "\n",
        "\n",
        "small_transform = torchvision.transforms.Resize((64, 64))\n",
        "big_transform = torchvision.transforms.Resize((224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:31: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "<>:31: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "C:\\Users\\shwes\\AppData\\Local\\Temp\\ipykernel_31340\\2526836154.py:31: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert(small_images.size() == (batch_size,3,64,64), \"size is \" + str(small_images.size()))\n",
            "11:15:20 - INFO: Starting epoch 0:\n",
            "  0%|          | 0/250 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 3/250 [00:00<00:39,  6.18it/s, MSE=3.09e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 7/250 [00:00<00:20, 11.80it/s, MSE=3e+8]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "6\n",
            "7\n",
            "8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 11/250 [00:01<00:16, 14.71it/s, MSE=2e+13]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "10\n",
            "11\n",
            "12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 15/250 [00:01<00:14, 16.52it/s, MSE=1.43e+18]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13\n",
            "14\n",
            "15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 17/250 [00:01<00:16, 14.12it/s, MSE=2.75e+20]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n",
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 19/250 [00:01<00:20, 11.17it/s, MSE=4.7e+22] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18\n",
            "19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 21/250 [00:02<00:23,  9.71it/s, MSE=1.11e+25]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 23/250 [00:02<00:25,  8.85it/s, MSE=2.33e+27]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22\n",
            "23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 25/250 [00:02<00:26,  8.37it/s, MSE=4.99e+24]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24\n",
            "25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 28/250 [00:02<00:29,  7.63it/s, MSE=4.47e+30]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26\n",
            "27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 30/250 [00:03<00:29,  7.55it/s, MSE=1.79e+33]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n",
            "29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 31/250 [00:03<00:28,  7.61it/s, MSE=4e+35]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30\n",
            "31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 33/250 [00:03<00:28,  7.66it/s, MSE=8.44e+37]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n",
            "33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 35/250 [00:03<00:28,  7.62it/s, MSE=inf]     "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34\n",
            "35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 37/250 [00:04<00:28,  7.60it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36\n",
            "37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 40/250 [00:04<00:28,  7.33it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38\n",
            "39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 42/250 [00:04<00:27,  7.50it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n",
            "41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 44/250 [00:05<00:27,  7.55it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42\n",
            "43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 45/250 [00:05<00:27,  7.59it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44\n",
            "45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 48/250 [00:05<00:26,  7.55it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46\n",
            "47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 49/250 [00:05<00:27,  7.29it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48\n",
            "49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 52/250 [00:06<00:26,  7.49it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 53/250 [00:06<00:26,  7.52it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52\n",
            "53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 56/250 [00:06<00:25,  7.58it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54\n",
            "55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 58/250 [00:06<00:24,  7.68it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "56\n",
            "57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▎       | 59/250 [00:07<00:24,  7.69it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "58\n",
            "59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 62/250 [00:07<00:24,  7.62it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60\n",
            "61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 63/250 [00:07<00:24,  7.65it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62\n",
            "63\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 65/250 [00:07<00:25,  7.37it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64\n",
            "65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 67/250 [00:08<00:24,  7.56it/s, MSE=inf]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66\n",
            "67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 70/250 [00:08<00:23,  7.63it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68\n",
            "69\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 71/250 [00:08<00:24,  7.17it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70\n",
            "71\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 74/250 [00:09<00:23,  7.38it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72\n",
            "73\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 75/250 [00:09<00:24,  7.16it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "74\n",
            "75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 78/250 [00:09<00:23,  7.39it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76\n",
            "77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 80/250 [00:09<00:22,  7.45it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78\n",
            "79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 81/250 [00:10<00:22,  7.45it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80\n",
            "81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 83/250 [00:10<00:24,  6.79it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82\n",
            "83\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 85/250 [00:10<00:20,  7.91it/s, MSE=nan]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84\n",
            "85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[36], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# ema.step_ema(ema_model, model)\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix(MSE\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     59\u001b[0m     logger\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem(), global_step\u001b[38;5;241m=\u001b[39mepoch \u001b[38;5;241m*\u001b[39m l \u001b[38;5;241m+\u001b[39m i)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from conditional_diffusion.ddpm_conditional import Diffusion\n",
        "from conditional_diffusion.ddpm_conditional import SummaryWriter\n",
        "from conditional_diffusion.ddpm_conditional import plot_images\n",
        "from conditional_diffusion.ddpm_conditional import save_images  \n",
        "from conditional_diffusion.modules import EMA\n",
        "import os\n",
        "import logging\n",
        "import copy\n",
        "\n",
        "\n",
        "run_name = \"Pong_Generator\"\n",
        "\n",
        "diffusion = Diffusion(img_size=64, device=device)\n",
        "logger = SummaryWriter(os.path.join(\"runs\", run_name))\n",
        "# ema = EMA(0.995)\n",
        "# ema_model = copy.deepcopy(net).eval().requires_grad_(False)\n",
        "l = len(trainloader)\n",
        "\n",
        "net.train()\n",
        "for epoch in range(300):  # loop over the dataset multiple times\n",
        "\n",
        "    logging.info(f\"Starting epoch {epoch}:\")\n",
        "    pbar = tqdm(trainloader)\n",
        "\n",
        "\n",
        "    for i, data in enumerate(pbar, 0):\n",
        "        print(i)\n",
        "        input, truth = data\n",
        "        small_images = truth[0] #64 by 64 image\n",
        "        #images = truth[1] #224 by 224 image\n",
        "        assert(small_images.size() == (batch_size,3,64,64), \"size is \" + str(small_images.size()))\n",
        "\n",
        "\n",
        "        \n",
        "        t = diffusion.sample_timesteps(small_images.shape[0]).to(device) #get <batch size> number of t's\n",
        "        x_t, small_noise = diffusion.noise_images(small_images, t) #TODO change the random noise to not be reallocated in memory so that the time complexity is less.\n",
        "\n",
        "        noise = big_transform(small_noise)#sadly i dont think this can be quickened\n",
        "\n",
        "        use_embedding = True\n",
        "        if np.random.random() < 0.1: #randomly dont use embedding to generate an image.\n",
        "            use_embedding = False\n",
        "        #forward\n",
        "        small_predicted_noise, predicted_noise, rew, don = net(input, t = t, noised_truth = x_t, use_embedding = use_embedding)\n",
        "\n",
        "        loss0 = small_img_criterion(small_noise,small_predicted_noise)\n",
        "        loss1 = img_criterion(noise,predicted_noise)\n",
        "        loss2 = rew_criterion(rew,truth[2])\n",
        "        loss3 = don_criterion(don,truth[3])\n",
        "        loss = loss0 + loss1 + loss2 + loss3\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # ema.step_ema(ema_model, model)\n",
        "\n",
        "        pbar.set_postfix(MSE=loss.item())\n",
        "        logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        net.eval()\n",
        "        labels = torch.arange(10).long().to(device)\n",
        "        sampled_images = net(input[0].unsqueeze(0))[0]\n",
        "        # ema_sampled_images = diffusion.sample(ema_model, n=len(labels), labels=labels)\n",
        "        plot_images(sampled_images)\n",
        "        save_images(sampled_images, os.path.join(\"results\", run_name, f\"{epoch}.jpg\"))\n",
        "        # save_images(ema_sampled_images, os.path.join(\"results\", run_name, f\"{epoch}_ema.jpg\"))\n",
        "        torch.save(net.state_dict(), os.path.join(\"models\", run_name, f\"ckpt.pt\"))\n",
        "        # torch.save(ema_model.state_dict(), os.path.join(\"models\", run_name, f\"ema_ckpt.pt\"))\n",
        "        torch.save(optimizer.state_dict(), os.path.join(\"models\", run_name, f\"optim.pt\"))\n",
        "        net.train()\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgRJ_RNBqA1b"
      },
      "outputs": [],
      "source": [
        "PATH = './models/pong_gen.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vkxLU375qA1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = Net(hidden_channels=hidden_channels)\n",
        "net.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "MWKouzwLqA1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "999it [00:20, 48.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 224, 224])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "input = None\n",
        "net.eval()\n",
        "for i, data in enumerate(trainloader, 0):\n",
        "    print(i)\n",
        "    input, truth = data\n",
        "    break\n",
        "\n",
        "output = net(input[0].unsqueeze(0))[0]\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "H3qb7meBqA1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0 255 255 ... 194 255   0]\n",
            " [255 144   0 ... 194   0 164]\n",
            " [  0   0   0 ...   0   0 255]\n",
            " ...\n",
            " [194 194   0 ... 121   0 151]\n",
            " [  0   0   0 ...   0   0 255]\n",
            " [  0 255 255 ... 255 255   0]]\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "image = Image.fromarray(input[0][0].cpu().detach().numpy())# true value\n",
        "image.show()\n",
        "\n",
        "image = Image.fromarray(output[0][0].cpu().detach().numpy())# predicted value\n",
        "image.show()\n",
        "print(output[0][0].cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u9O5pKEqA1d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'observations' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gif \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mfromarray(observation) \u001b[38;5;28;01mfor\u001b[39;00m observation \u001b[38;5;129;01min\u001b[39;00m \u001b[43mobservations\u001b[49m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m      4\u001b[0m     gif\u001b[38;5;241m.\u001b[39mappend(image)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'observations' is not defined"
          ]
        }
      ],
      "source": [
        "gif = []\n",
        "images = [Image.fromarray(observation) for observation in observations]\n",
        "for image in images:\n",
        "    gif.append(image)\n",
        "gif[0].save('temp/result.gif', save_all=True,optimize=False, append_images=gif[1:], loop=0)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
