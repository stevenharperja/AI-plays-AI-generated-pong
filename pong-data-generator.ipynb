{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from\n",
    "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit4/unit4.ipynb#scrollTo=V8oadoJSWp7C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[atari] in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from gym[atari]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from gym[atari]) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from gym[atari]) (0.0.8)\n",
      "Requirement already satisfied: ale-py~=0.8.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from gym[atari]) (0.8.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from ale-py~=0.8.0->gym[atari]) (6.4.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license] in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from autorom[accept-rom-license]) (8.1.7)\n",
      "Requirement already satisfied: requests in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from autorom[accept-rom-license]) (2.31.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from autorom[accept-rom-license]) (0.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from click->autorom[accept-rom-license]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from requests->autorom[accept-rom-license]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from requests->autorom[accept-rom-license]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from requests->autorom[accept-rom-license]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from requests->autorom[accept-rom-license]) (2024.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (2.3.0+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: torch in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#!apt install python-opengl\n",
    "#!apt install ffmpeg\n",
    "#!apt install xvfb\n",
    "#!pip install pyvirtualdisplay\n",
    "#!pip install pyglet==1.5.1\n",
    "#!pip install imageio\n",
    "!pip install gym[atari]\n",
    "!pip install autorom[accept-rom-license]\n",
    "!pip install torchvision\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Virtual display\n",
    "# from pyvirtualdisplay import Display\n",
    "\n",
    "# virtual_display = Display(visible=0, size=(1400, 900))\n",
    "# virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Gym\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"ALE/Pong-v5\"\n",
    "# Create the env\n",
    "env = gym.make(env_id,obs_type=\"grayscale\",full_action_space=False)\n",
    "\n",
    "# Create the evaluation env\n",
    "eval_env = gym.make(env_id,obs_type=\"grayscale\",full_action_space=False)\n",
    "\n",
    "# Get the state space and action space\n",
    "s_size = gym.spaces.utils.flatten_space(env.observation_space).shape[0]\n",
    "a_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____OBSERVATION SPACE_____ \n",
      "\n",
      "The State Space is:  33600\n",
      "Sample observation [[ 90  94  97 ...  22 244 235]\n",
      " [159 223 131 ...  70   7  90]\n",
      " [204  49  84 ... 175 157 253]\n",
      " ...\n",
      " [155  39 166 ... 184  95 171]\n",
      " [ 35  47 112 ... 229 212 241]\n",
      " [ 61 239  38 ... 129 102 161]]\n"
     ]
    }
   ],
   "source": [
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"The State Space is: \", s_size)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____ACTION SPACE_____ \n",
      "\n",
      "The Action Space is:  6\n",
      "Action Space Sample 5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"The Action Space is: \", a_size)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import sys\n",
    "\n",
    "class Saver():\n",
    "    \"\"\"\n",
    "    Class to save the output and input to an environment as tensors which can be used to train the nn\n",
    "    \"\"\"\n",
    "    def __init__(self,save_dir,in_transform = None, out_transform = None, small_transform = None,file_limit = 1000) -> None:\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.observations = deque()#maxsize=3)\n",
    "        self.actions = deque()#maxsize=1)\n",
    "        self.rewards = deque()#maxsize=1)\n",
    "        self.dones = deque()#maxsize=1)\n",
    "        self.h=None\n",
    "        self.w=None\n",
    "        self.file_limit = file_limit\n",
    "        self.in_transform = in_transform\n",
    "        self.out_transform = out_transform\n",
    "        self.small_transform = small_transform\n",
    "\n",
    "        os.makedirs(os.path.dirname(save_dir), exist_ok=True)\n",
    "\n",
    "    def add_transition(self,observation, action, reward, done):\n",
    "        \"\"\"\n",
    "        Observations: What the agent sees (dimensions are 210 x 160)\n",
    "        Actions: What the agent does (dimensions are 6 x 1)\n",
    "        Rewards: The reward the agent gets (range is -1 to 1)?\n",
    "        Dones: If the episode is over (True or False)\n",
    "        \"\"\"\n",
    "        self.observations.append(observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "        if len(self.observations) == 3:\n",
    "            self._save_transitions()\n",
    "            #clear screen of 3 screens ago.\n",
    "            self.observations.popleft()\n",
    "        \n",
    "        #clear old values\n",
    "        if len(self.actions) == 1:\n",
    "            self.actions.popleft()\n",
    "        if len(self.rewards) == 1:\n",
    "            self.rewards.popleft()\n",
    "        if len(self.dones) == 1:\n",
    "            self.dones.popleft()\n",
    "\n",
    "    def _transform(self, input,truth):\n",
    "        if self.in_transform == None or self.out_transform == None:\n",
    "            return(input,truth)\n",
    "        input = self.in_transform(input)\n",
    "        #make the pong image bigger\n",
    "        truth[0] = self.out_transform(truth[0])\n",
    "        #add a small version of the pong image into index 0.\n",
    "        truth = [self.small_transform(truth[0])] + truth\n",
    "\n",
    "        return input,truth\n",
    "\n",
    "    def _convert_to_tensors(self):\n",
    "        if self.h == None or self.w == None:\n",
    "            h = self.observations[0].shape[0] #height of a pong image\n",
    "            w = self.observations[0].shape[1] #width of a pong image\n",
    "\n",
    "        #take 2 images as input, return one image (the model should need two input images to determine ball velocity)\n",
    "        #expand action to a matrix the size of a pong image, and add it as a seperate channel in a tensor image later\n",
    "        act = np.broadcast_to(self.actions[0], (h,w) )\n",
    "        rew = self.rewards[0]\n",
    "        don = self.dones[0]\n",
    "\n",
    "\n",
    "        input = np.stack((self.observations[0], self.observations[1], act), axis=0) #put the channels together so my life is easier and the nn pays a lot of attention to act\n",
    "        truth = (self.observations[2],rew,don) #tuple of outputs\n",
    "        \n",
    "        \n",
    "\n",
    "        input = torch.tensor(input,dtype=torch.float)\n",
    "        truth = [\n",
    "            torch.tensor(np.expand_dims(truth[0],axis=0),dtype=torch.float).repeat((3,1,1)),\n",
    "            torch.unsqueeze(torch.tensor(truth[1],dtype=torch.float),dim=0),\n",
    "            torch.unsqueeze(torch.tensor(truth[2],dtype=torch.float),dim=0),\n",
    "        ]\n",
    "        assert input.shape == (3,h,w)\n",
    "        assert truth[0].shape == (3,h,w)\n",
    "        assert truth[1].shape == (1,), \"shape is {}\".format(truth[1].shape)\n",
    "        assert truth[2].shape == (1,)\n",
    "\n",
    "        return input,truth\n",
    "\n",
    "    def _save_transitions(self):\n",
    "        #change bool in dones to floats\n",
    "        for i in range(len(self.dones)):\n",
    "            self.dones[i] = float(self.dones[i])\n",
    "\n",
    "        existing_files = [f for f in listdir(self.save_dir) if isfile(join(self.save_dir, f))]\n",
    "        j = None\n",
    "        if existing_files:\n",
    "            #This grabs the largest integer out of all the filenames (filter the string for digit chars, convert those chars to an int)\n",
    "            j = max([int(''.join([c for c in f if c.isdigit()])) for f in existing_files])\n",
    "        else:\n",
    "            j = -1\n",
    "        j += 1\n",
    "\n",
    "        if j >= self.file_limit:\n",
    "            sys.exit(0)\n",
    "\n",
    "        input,truth = self._convert_to_tensors()\n",
    "\n",
    "        input,truth = self._transform(input,truth)\n",
    "\n",
    "        torch.save(input,self.save_dir+\"input{i}.pt\".format(i=j))\n",
    "        torch.save((truth),self.save_dir+\"truth{i}.pt\".format(i=j))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "save_dir = \"diffusion_training_data/\"\n",
    "imagenet_stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "#TODO add a transform for, and also save, a small version of the truth image.\n",
    "\n",
    "in_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    # torchvision.transforms.Normalize(*imagenet_stats)\n",
    "                                      ])\n",
    "out_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "                                      ])\n",
    "small_transform = out_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((64, 64)),\n",
    "                                      ])\n",
    "saver = Saver(save_dir,in_transform=in_transform,out_transform=out_transform, small_transform=small_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pong(n_episodes, max_t):\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()[0]\n",
    "        for t in range(max_t):\n",
    "            action = env.action_space.sample()\n",
    "            state, reward, terminated, truncated, info = env.step(action)\n",
    "            saver.add_transition(state, action, reward, terminated or truncated)\n",
    "            if terminated or truncated:\n",
    "                break \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shwes\\Projects\\AI-plays-AI-generated-pong\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 10\n",
    "max_t = 1000\n",
    "run_pong(n_episodes,max_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
