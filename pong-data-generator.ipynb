{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from\n",
    "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit4/unit4.ipynb#scrollTo=V8oadoJSWp7C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym[atari]\n",
      "  Using cached gym-0.26.2-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from gym[atari]) (1.26.4)\n",
      "Collecting cloudpickle>=1.2.0 (from gym[atari])\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gym-notices>=0.0.4 (from gym[atari])\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting ale-py~=0.8.0 (from gym[atari])\n",
      "  Using cached ale_py-0.8.1-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting importlib-resources (from ale-py~=0.8.0->gym[atari])\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached ale_py-0.8.1-cp311-cp311-win_amd64.whl (952 kB)\n",
      "Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: gym-notices, importlib-resources, cloudpickle, gym, ale-py\n",
      "Successfully installed ale-py-0.8.1 cloudpickle-3.0.0 gym-0.26.2 gym-notices-0.0.8 importlib-resources-6.4.0\n",
      "Collecting autorom[accept-rom-license]\n",
      "  Using cached AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting click (from autorom[accept-rom-license])\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting requests (from autorom[accept-rom-license])\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
      "  Using cached AutoROM.accept_rom_license-0.6.1-py3-none-any.whl\n",
      "Requirement already satisfied: colorama in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from click->autorom[accept-rom-license]) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->autorom[accept-rom-license])\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->autorom[accept-rom-license])\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->autorom[accept-rom-license])\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->autorom[accept-rom-license])\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: urllib3, idna, click, charset-normalizer, certifi, requests, AutoROM.accept-rom-license, autorom\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 idna-3.7 requests-2.31.0 urllib3-2.2.1\n",
      "Requirement already satisfied: torchvision in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (2.3.0+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: torch in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shwes\\projects\\ai-plays-ai-generated-pong\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#!apt install python-opengl\n",
    "#!apt install ffmpeg\n",
    "#!apt install xvfb\n",
    "#!pip install pyvirtualdisplay\n",
    "#!pip install pyglet==1.5.1\n",
    "#!pip install imageio\n",
    "!pip install gym[atari]\n",
    "!pip install autorom[accept-rom-license]\n",
    "!pip install torchvision\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Virtual display\n",
    "# from pyvirtualdisplay import Display\n",
    "\n",
    "# virtual_display = Display(visible=0, size=(1400, 900))\n",
    "# virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Gym\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shwes\\Projects\\AI-plays-AI-generated-pong\\.venv\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (210, 160)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env_id = \"ALE/Pong-v5\"\n",
    "# Create the env\n",
    "env = gym.make(env_id,obs_type=\"grayscale\",full_action_space=False)\n",
    "\n",
    "# Create the evaluation env\n",
    "eval_env = gym.make(env_id,obs_type=\"grayscale\",full_action_space=False)\n",
    "\n",
    "# Get the state space and action space\n",
    "s_size = gym.spaces.utils.flatten_space(env.observation_space).shape[0]\n",
    "a_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____OBSERVATION SPACE_____ \n",
      "\n",
      "The State Space is:  33600\n",
      "Sample observation [[ 16  41 254 ...  57  90 230]\n",
      " [207 228 214 ... 230 179 158]\n",
      " [253  47  26 ... 177  23 177]\n",
      " ...\n",
      " [ 81 212 148 ...  76  21 202]\n",
      " [ 45 146 234 ... 136 148 213]\n",
      " [ 45  80   5 ... 232  92  10]]\n"
     ]
    }
   ],
   "source": [
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"The State Space is: \", s_size)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____ACTION SPACE_____ \n",
      "\n",
      "The Action Space is:  6\n",
      "Action Space Sample 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"The Action Space is: \", a_size)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import sys\n",
    "\n",
    "class Saver():\n",
    "    \"\"\"\n",
    "    Class to save the output and input to an environment as tensors which can be used to train the nn\n",
    "    \"\"\"\n",
    "    def __init__(self,save_dir,in_transform = None, out_transform = None,file_limit = 1000) -> None:\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.observations = deque()#maxsize=3)\n",
    "        self.actions = deque()#maxsize=1)\n",
    "        self.rewards = deque()#maxsize=1)\n",
    "        self.dones = deque()#maxsize=1)\n",
    "        self.h=None\n",
    "        self.w=None\n",
    "        self.file_limit = file_limit\n",
    "        self.in_transform = in_transform\n",
    "        self.out_transform = out_transform\n",
    "\n",
    "        os.makedirs(os.path.dirname(save_dir), exist_ok=True)\n",
    "\n",
    "    def add_transition(self,observation, action, reward, done):\n",
    "        \"\"\"\n",
    "        Observations: What the agent sees (dimensions are 210 x 160)\n",
    "        Actions: What the agent does (dimensions are 6 x 1)\n",
    "        Rewards: The reward the agent gets (range is -1 to 1)?\n",
    "        Dones: If the episode is over (True or False)\n",
    "        \"\"\"\n",
    "        self.observations.append(observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "        if len(self.observations) == 3:\n",
    "            self._save_transitions()\n",
    "            #clear screen of 3 screens ago.\n",
    "            self.observations.popleft()\n",
    "        \n",
    "        #clear old values\n",
    "        if len(self.actions) == 1:\n",
    "            self.actions.popleft()\n",
    "        if len(self.rewards) == 1:\n",
    "            self.rewards.popleft()\n",
    "        if len(self.dones) == 1:\n",
    "            self.dones.popleft()\n",
    "\n",
    "    def _transform(self, input,truth):\n",
    "        if self.in_transform == None or self.out_transform == None:\n",
    "            return(input,truth)\n",
    "        input = self.in_transform(input)\n",
    "        truth[0] = self.out_transform(truth[0])\n",
    "        return input,truth\n",
    "\n",
    "    def _convert_to_tensors(self):\n",
    "        if self.h == None or self.w == None:\n",
    "            h = self.observations[0].shape[0] #height of a pong image\n",
    "            w = self.observations[0].shape[1] #width of a pong image\n",
    "\n",
    "        #take 2 images as input, return one image (the model should need two input images to determine ball velocity)\n",
    "        #expand action to a matrix the size of a pong image, and add it as a seperate channel in a tensor image later\n",
    "        act = np.broadcast_to(self.actions[0], (h,w) )\n",
    "        rew = self.rewards[0]\n",
    "        don = self.dones[0]\n",
    "\n",
    "\n",
    "        input = np.stack((self.observations[0], self.observations[1], act), axis=0) #put the channels together so my life is easier and the nn pays a lot of attention to act\n",
    "        truth = (self.observations[2],rew,don) #tuple of outputs\n",
    "        \n",
    "        \n",
    "\n",
    "        input = torch.tensor(input,dtype=torch.float)\n",
    "        truth = [\n",
    "            torch.tensor(np.expand_dims(truth[0],axis=0),dtype=torch.float),\n",
    "            torch.unsqueeze(torch.tensor(truth[1],dtype=torch.float),dim=0),\n",
    "            torch.unsqueeze(torch.tensor(truth[2],dtype=torch.float),dim=0),\n",
    "        ]\n",
    "        assert input.shape == (3,h,w)\n",
    "        assert truth[0].shape == (1,h,w)\n",
    "        assert truth[1].shape == (1,), \"shape is {}\".format(truth[1].shape)\n",
    "        assert truth[2].shape == (1,)\n",
    "\n",
    "        return input,truth\n",
    "\n",
    "    def _save_transitions(self):\n",
    "        #change bool in dones to floats\n",
    "        for i in range(len(self.dones)):\n",
    "            self.dones[i] = float(self.dones[i])\n",
    "\n",
    "        existing_files = [f for f in listdir(self.save_dir) if isfile(join(self.save_dir, f))]\n",
    "        j = None\n",
    "        if existing_files:\n",
    "            #This grabs the largest integer out of all the filenames (filter the string for digit chars, convert those chars to an int)\n",
    "            j = max([int(''.join([c for c in f if c.isdigit()])) for f in existing_files])\n",
    "        else:\n",
    "            j = -1\n",
    "        j += 1\n",
    "\n",
    "        if j >= self.file_limit:\n",
    "            sys.exit(0)\n",
    "\n",
    "        input,truth = self._convert_to_tensors()\n",
    "\n",
    "        input,truth = self._transform(input,truth)\n",
    "\n",
    "        torch.save(input,self.save_dir+\"input{i}.pt\".format(i=j))\n",
    "        torch.save((truth),self.save_dir+\"truth{i}.pt\".format(i=j))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "save_dir = \"diffusion_training_data/\"\n",
    "imagenet_stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "in_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    # torchvision.transforms.Normalize(*imagenet_stats)\n",
    "                                      ])\n",
    "out_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "                                      ])\n",
    "saver = Saver(save_dir,in_transform=in_transform,out_transform=out_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pong(n_episodes, max_t):\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()[0]\n",
    "        for t in range(max_t):\n",
    "            action = env.action_space.sample()\n",
    "            state, reward, terminated, truncated, info = env.step(action)\n",
    "            saver.add_transition(state, action, reward, terminated or truncated)\n",
    "            if terminated or truncated:\n",
    "                break \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shwes\\Projects\\AI-plays-AI-generated-pong\\.venv\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shwes\\Projects\\AI-plays-AI-generated-pong\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 10\n",
    "max_t = 1000\n",
    "run_pong(n_episodes,max_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
